{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df8573e1",
   "metadata": {},
   "source": [
    "## Bias and efficiency\n",
    "The focus of these simulations is to show how altering a model, to avoid collinear regressors, can result in biased estimates of parameter estimates. Although efficiency is preferred, it is less important than bias in terms of interpreting contrast estimates.\n",
    "\n",
    "An fMRI model should include a regressor for each stimulus that occurs.  Since the cue/fixation/probe/feedback stimuli are presented without any baseline fixation between them, modeling all stimuli is often avoided, presumably in fear that the lowered efficiency will reduce power.  The less appreciated, more important issue is the bias that results when this modeling practice is used.\n",
    "\n",
    "NOTE: This version is refactored by RP based on the code in MID_sim_groupmodel_manuscript.ipynb. Changes include:\n",
    "\n",
    "- removing the fix only model (since it's not directly relevant to the point of the paper)\n",
    "- moving all of the functions to external files\n",
    "- testing of all functions (`make test`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d89d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_1samp\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "from simulation_funcs import (\n",
    "    get_subdata_long,\n",
    "    insert_jitter,\n",
    "    create_design_matrices,\n",
    "    generate_data_nsim,\n",
    "    get_beta_dicts,\n",
    "    create_contrasts,\n",
    "    make_analysis_label,\n",
    "    sim_group_models_parallel,\n",
    ")\n",
    "\n",
    "from simulation_plotting import (\n",
    "    plot_proportion_sig,\n",
    "    plot_contrast_estimates,\n",
    "    plot_results,\n",
    "    plot_dict_of_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67d1a5",
   "metadata": {},
   "source": [
    "## Simulation setup\n",
    "\n",
    "These simulations focus on the following models:\n",
    "* saturated:  Models 5 cue regressors (2 levels of gain/loss and no money at stake), 5 similar fixation regressors, 5 probe regressors (when RT is unknown) and 10 feedback regressors (5 trial types x hit/miss)\n",
    "* cue only: Model includes 5 cue regressors and 10 feedback regressors\n",
    "* cuefix: Model includes 5 regressors using the cue onset and cue+fixation durations and 10 feedback regressors\n",
    "* fix only: Model includes 5 fixation regressors and 10 feedback regressors\n",
    "\n",
    "The models for  one subject are displayed below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436097b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sub = 1\n",
    "events = get_subdata_long(sub)\n",
    "designs = create_design_matrices(events, conv_resolution=0.2, tr=1)\n",
    "print(designs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15, 20))\n",
    "ax_flat = ax.flatten()\n",
    "for i, desname in enumerate(designs.keys()):\n",
    "    reg_names = designs[desname].columns\n",
    "    trial_types = [\n",
    "        val.replace('FEEDBACK_HIT_', '')\n",
    "        for val in reg_names\n",
    "        if 'FEEDBACK_HIT_' in val\n",
    "    ]\n",
    "    stim_types = [\n",
    "        val.replace('_LargeLoss', '')\n",
    "        for val in reg_names\n",
    "        if 'LargeLoss' in val\n",
    "    ]\n",
    "    regressors_ordered = [\n",
    "        f'{stim_type}_{trial_type}'\n",
    "        for trial_type in trial_types\n",
    "        for stim_type in stim_types\n",
    "    ]\n",
    "    plot_design_matrix(\n",
    "        designs[desname].reindex(regressors_ordered, axis=1), ax=ax_flat[i]\n",
    "    )\n",
    "    ax_flat[i].set_title(desname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79489a",
   "metadata": {},
   "source": [
    "### The main contrasts of interest\n",
    "* Anticipation: Win - Neutral\n",
    "* Anticipation: Large Win - Neutral\n",
    "* Feedback: WinHit - Neutral Miss\n",
    "* Feedback: Large Win Hit - Large Win Miss\n",
    "The definitions for each of these contrasts for each model are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3b16c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "contrast_strings, contrasts_matrices, c_pinv_xmats = create_contrasts(designs)\n",
    "for key, contrasts in contrast_strings.items():\n",
    "    print(f'\\n Contrasts for {key} model')\n",
    "    for contrast_name, contrast_string in contrasts.items():\n",
    "        if ':' in contrast_name:\n",
    "            print(f'{contrast_name}: {contrast_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb53747",
   "metadata": {},
   "source": [
    "### Effect sizes and variance settings\n",
    "The model used to simulate data was the saturated model.  The null model (all true betas were set to 0) and 6 non-null models were simulated, where the nonzero betas are define below in `beta_dicts`. It is hard to know what a reasonable within- and between-subject variance would be.  We simply set the between-subject variance to 1 and the within-subject residual variance was set to 1.  As such, we cannot make any claims about power differences here, since that would require properly setting the variances to realistic values based on data.  Instead, we have opted to run the model comparisons on real data to show any power differences, barring the presence of bias.\n",
    "\n",
    "A totall of 1000 simulated data sets were generated.  Each data set has 107 subjects and the timings are based on the AHRB data.  Data were simulated, with the given beta settings and then contrasts were estimated using each model.  The contrast estimates were then averaged over subjects and the inference from the 1-sample t-test was used to determine significance using a 2-tailed test p-value < 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f41250",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Run all simulations without jitter\n",
    "#  Note, the error for subject 5 is due to a problem with their file, so they have been omitted from the simulations.\n",
    "beta_dicts = get_beta_dicts()\n",
    "\n",
    "beta_sub_sd = 1\n",
    "noise_sd = 1\n",
    "nsims = 1000\n",
    "results = {}\n",
    "\n",
    "for beta_dict in beta_dicts:\n",
    "    figure_label = make_analysis_label(beta_dict)\n",
    "    results[figure_label], _ = sim_group_models_parallel(\n",
    "        beta_dict,\n",
    "        noise_sd,\n",
    "        beta_sub_sd,\n",
    "        nsims=nsims,\n",
    "        conv_resolution=0.2,\n",
    "        tr=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0f760",
   "metadata": {},
   "source": [
    "## Type I errors are controlled when there is no signal\n",
    "The following figure show the proportion of significant results out of the 1000 simulated data sets and the distributions of the group contrast estimates.  Bars and violins that are opaque (all in the this figure) reflect contrasts that should be null.  In the left panel (Proportion significant) all bars reflect Type I error rates and these are controlled for all contrasts and models.  In the right panel, since all contrasts reflect null effects, the distributions of the coefficient estimates should be, and are, centered about 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630400f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict_of_results({'Null model': results['Null model']}, contrasts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4ec73",
   "metadata": {},
   "source": [
    "## Parsing the results\n",
    "Error rates, power and bias for the four contrasts of interest. Each panel grouping in the following figure refers to different settings where some parameters are nonzero as indicated in the panel pair figure headings.  Solid colored bars/violins reflect contrasts that should have signal, while opaque reflects null models.  If an opaque bar is above 0.05 (dashed red line), this indicates an inflated Type I error for that model and contrast combination.  The corresponding distributions of coefficient estimates will reflect the bias that occurs when the error rate is inflated.  Notably, bias can occur for null and non-null effects.\n",
    "\n",
    "When both the small and large gain cue regressors have nonzero betas (=0.4), the fix only model cannot fully capture the cue effect that is present and this left over signal biases the feedback estimates, which inflates the type I error. In the cuefix model, since the model does not properly fit the signal (the duration of the regressor is too long), since the cuefix regressor is collinear with the feedback regressors, this ends up biasing the feedback estimate and inflating the..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aac361",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "results_plot = results.copy()\n",
    "results_plot.pop('Null model')\n",
    "plot_dict_of_results(results_plot, contrasts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c01a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, result in results.items():\n",
    "    plot_results(\n",
    "        result[(result['contrast'].str.contains(':') == False)],\n",
    "        name,\n",
    "        stacked=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753ad85",
   "metadata": {},
   "source": [
    "## Repeat the above, but add a jittered ITI\n",
    "\n",
    "These simulations add a jitter between 2-5s between the offset of the feedback of one trial and the onset of the cue in the following trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_jitter = {}\n",
    "\n",
    "for beta_dict in beta_dicts:\n",
    "    figure_label = make_analysis_label(beta_dict)\n",
    "    results_jitter[figure_label], _ = sim_group_models_parallel(\n",
    "        beta_dict,\n",
    "        noise_sd,\n",
    "        beta_sub_sd,\n",
    "        nsims=nsims,\n",
    "        conv_resolution=0.2,\n",
    "        tr=1,\n",
    "        jitter=False,\n",
    "        jitter_iti_min=2,\n",
    "        jitter_iti_max=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4108dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_jitter_plot = results_jitter.copy()\n",
    "results_jitter_plot.pop('Null model')\n",
    "plot_dict_of_results(results_jitter_plot, contrasts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238cda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, result in results_jitter.items():\n",
    "    plot_results(\n",
    "        result[(result['contrast'].str.contains(':') == False)],\n",
    "        name,\n",
    "        stacked=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
